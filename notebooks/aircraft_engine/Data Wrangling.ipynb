{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source ###\n",
    "\n",
    "___Training Data:___  The aircraft engine run-to-failure data.\n",
    "[download trianing data](http://azuremlsamples.azureml.net/templatedata/PM_train.txt)  \n",
    "___Test Data:___ The aircraft engine operating data without failure events recorded.\n",
    "[download test data](http://azuremlsamples.azureml.net/templatedata/PM_test.txt)  \n",
    "___Ground Truth Data:___ The true remaining cycles for each engine in the testing data.\n",
    "[download truth data](http://azuremlsamples.azureml.net/templatedata/PM_truth.txt)  \n",
    "\n",
    "For simplicity, data files have been downloaded to local Data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Columns\n",
    "\n",
    "•\t__id__: is the engine ID, ranging from 1 to 100  \n",
    "•\t__cycle__: per engine sequence, starts from 1 to the cycle number where failure had happened (trining data only) \n",
    "•\t__setting1__ to __setting3__: engine operational settings  \n",
    "•\t__s1__ to __s21__: sensors measurements  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset column names:\n",
    "\n",
    "col_names = ['id','cycle','setting1','setting2','setting3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1       2       3      4       5       6        7        8      9  ...  \\\n",
       "0   1   1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60  14.62 ...   \n",
       "1   1   2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14  14.62 ...   \n",
       "2   1   3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20  14.62 ...   \n",
       "3   1   4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87  14.62 ...   \n",
       "4   1   5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22  14.62 ...   \n",
       "\n",
       "        18      19    20   21    22     23     24       25  26  27  \n",
       "0  8138.62  8.4195  0.03  392  2388  100.0  39.06  23.4190 NaN NaN  \n",
       "1  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236 NaN NaN  \n",
       "2  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442 NaN NaN  \n",
       "3  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739 NaN NaN  \n",
       "4  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044 NaN NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load training data\n",
    "\n",
    "df_train_raw = pd.read_csv('data/PM_train.txt', sep = ' ', header=None)\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For argument \"inplace\" expected type bool, received type str.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3706d3071742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#drop extra space columnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_train_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3091\u001b[0m              inplace=False, errors='raise'):\n\u001b[0;32m   3092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3093\u001b[1;33m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inplace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3095\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_validators.py\u001b[0m in \u001b[0;36mvalidate_bool_kwarg\u001b[1;34m(value, arg_name)\u001b[0m\n\u001b[0;32m    224\u001b[0m         raise ValueError('For argument \"{arg}\" expected type bool, received '\n\u001b[0;32m    225\u001b[0m                          'type {typ}.'.format(arg=arg_name,\n\u001b[1;32m--> 226\u001b[1;33m                                               typ=type(value).__name__))\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For argument \"inplace\" expected type bool, received type str."
     ]
    }
   ],
   "source": [
    "#drop extra space columnn\n",
    "\n",
    "df_train_raw.drop([26,27], axis=1, inplace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assign column names\n",
    "\n",
    "df_train_raw.columns = col_names\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get some stat\n",
    "\n",
    "df_train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 100 engines. each engine has between 1 to 362 cycles (average of 108 cycles per engine). The last cycle for each engine represents the cycle when failure had happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the data types\n",
    "\n",
    "df_train_raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for NaN values\n",
    "\n",
    "df_train_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values. This is a clean dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load test data\n",
    "\n",
    "df_test_raw = pd.read_csv('data/PM_test.txt', sep = ' ', header=None)\n",
    "df_test_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop extra space columnn\n",
    "df_test_raw.drop([26,27], axis=1, inplace='True')\n",
    "\n",
    "#assign column names\n",
    "df_test_raw.columns = col_names\n",
    "df_test_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get some stat on test data\n",
    "\n",
    "df_test_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as training data, there are 100 engines, each engine has between 1 to 303 cycles (average of 76 cycles per engine). But this time, failure cycle was not provided.  \n",
    "\n",
    "Failure events for test data - remaining cycles before failure (TTF) - were provided in a separate truth file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Truth Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the truth data - actual 'ttf' for test data\n",
    "\n",
    "df_truth = pd.read_csv('data/PM_truth.txt', sep = ' ', header=None)\n",
    "df_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop extra empty column in the truth data and rename remaining 'ttf'\n",
    "\n",
    "df_truth.drop([1], axis=1, inplace='True')\n",
    "df_truth.columns = ['ttf']\n",
    "df_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get some stat on truth data\n",
    "\n",
    "df_truth.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get meaningful test data, we need to merge the truth data (TTF) with last cycle for each engine in the test data. This will give us a test set of 100 engines with their TTF data. Will do that later when we create regression and classification labels for both training and test data. \n",
    "\n",
    "But now let us add some features to smooth the sensors reading: rolling average and rolling standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper function to create features based on smoothing the time series for sensors by adding rolling mean and rolling standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_features(df_in, rolling_win_size):\n",
    "    \n",
    "    \"\"\"Add rolling average and rolling standard deviation for sensors readings using fixed rolling window size.\n",
    "    \n",
    "    Args:\n",
    "            df_in (dataframe)     : The input dataframe to be proccessed (training or test) \n",
    "            rolling_win_size (int): The window size, number of cycles for applying the rolling function\n",
    "        \n",
    "    Reurns:\n",
    "            dataframe: contains the input dataframe with additional rolling mean and std for each sensor\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sensor_cols = ['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n",
    "    \n",
    "    sensor_av_cols = [nm.replace('s', 'av') for nm in sensor_cols]\n",
    "    sensor_sd_cols = [nm.replace('s', 'sd') for nm in sensor_cols]\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    ws = rolling_win_size\n",
    "    \n",
    "    #calculate rolling stats for each engine id\n",
    "    \n",
    "    for m_id in pd.unique(df_in.id):\n",
    "    \n",
    "        # get a subset for each engine sensors\n",
    "        df_engine = df_in[df_in['id'] == m_id]\n",
    "        df_sub = df_engine[sensor_cols]\n",
    "\n",
    "    \n",
    "        # get rolling mean for the subset\n",
    "        av = df_sub.rolling(ws, min_periods=1).mean()\n",
    "        av.columns = sensor_av_cols\n",
    "    \n",
    "        # get the rolling standard deviation for the subset\n",
    "        sd = df_sub.rolling(ws, min_periods=1).std().fillna(0)\n",
    "        sd.columns = sensor_sd_cols\n",
    "    \n",
    "        # combine the two new subset dataframes columns to the engine subset\n",
    "        new_ftrs = pd.concat([df_engine,av,sd], axis=1)\n",
    "    \n",
    "        # add the new features rows to the output dataframe\n",
    "        df_out = pd.concat([df_out,new_ftrs])\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create helper function to add the regression and classification labels to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_train_data (df_in, period):\n",
    "    \n",
    "    \"\"\"Add regression and classification labels to the training data.\n",
    "\n",
    "        Regression label: ttf (time-to-failure) = each cycle# for an engine subtracted from the last cycle# of the same engine\n",
    "        Binary classification label: label_bnc = if ttf is <= parameter period then 1 else 0 (values = 0,1)\n",
    "        Multi-class classification label: label_mcc = 2 if ttf <= 0.5* parameter period , 1 if ttf<= parameter period, else 2\n",
    "        \n",
    "      Args:\n",
    "          df_in (dataframe): The input training data\n",
    "          period (int)     : The number of cycles for TTF segmentation. Used to derive classification labels\n",
    "          \n",
    "      Returns:\n",
    "          dataframe: The input dataframe with regression and classification labels added\n",
    "          \n",
    "    \"\"\"\n",
    "    \n",
    "    #create regression label\n",
    "    \n",
    "    #make a dataframe to hold the last cycle for each enginge in the dataset\n",
    "    df_max_cycle = pd.DataFrame(df_in.groupby('id')['cycle'].max())\n",
    "    df_max_cycle.reset_index(level=0, inplace=True)\n",
    "    df_max_cycle.columns = ['id', 'last_cycle']\n",
    "    \n",
    "    #add time-to-failure ttf as a new column - regression label\n",
    "    df_in = pd.merge(df_in, df_max_cycle, on='id')\n",
    "    df_in['ttf'] = df_in['last_cycle'] - df_in['cycle']\n",
    "    df_in.drop(['last_cycle'], axis=1, inplace='True')\n",
    "    \n",
    "    #create binary classification label\n",
    "    df_in['label_bnc'] = df_in['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
    "    \n",
    "    #create multi-class classification label\n",
    "    df_in['label_mcc'] = df_in['ttf'].apply(lambda x: 2 if x <= period/2 else 1 if x <= period else 0)\n",
    "    \n",
    "    return df_in\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create helper function to add the regression and classification labels to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_test_data(df_test_in, df_truth_in, period):\n",
    "    \n",
    "    \"\"\"Add regression and classification labels to the test data.\n",
    "\n",
    "        Regression label: ttf (time-to-failure) = extract the last cycle for each enginge and then merge the record with the truth data\n",
    "        Binary classification label: label_bnc = if ttf is <= parameter period then 1 else 0 (values = 0,1)\n",
    "        Multi-class classification label: label_mcc = 2 if ttf <= 0.5* parameter period , 1 if ttf<= parameter period, else 2\n",
    "        \n",
    "      Args:\n",
    "          df_in (dataframe): The input training data\n",
    "          period (int)     : The number of cycles for TTF segmentation. Used to derive classification labels\n",
    "          \n",
    "      Returns:\n",
    "          dataframe: The input dataframe with regression and classification labels added\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_tst_last_cycle = pd.DataFrame(df_test_in.groupby('id')['cycle'].max())\n",
    "    \n",
    "    df_tst_last_cycle.reset_index(level=0, inplace=True)\n",
    "    df_tst_last_cycle.columns = ['id', 'last_cycle']\n",
    "    \n",
    "    df_test_in = pd.merge(df_test_in, df_tst_last_cycle, on='id')\n",
    "\n",
    "\n",
    "    df_test_in = df_test_in[df_test_in['cycle'] == df_test_in['last_cycle']]\n",
    "\n",
    "    df_test_in.drop(['last_cycle'], axis=1, inplace='True')\n",
    "    \n",
    "    df_test_in.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_test_in = pd.concat([df_test_in, df_truth], axis=1)\n",
    "    \n",
    "    #create binary classification label\n",
    "    df_test_in['label_bnc'] = df_test_in['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
    "    \n",
    "    #create multi-class classification label\n",
    "    df_test_in['label_mcc'] = df_test_in['ttf'].apply(lambda x: 2 if x <= period/2 else 1 if x <= period else 0)\n",
    "\n",
    "    return df_test_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of these functions, let us prepare training and test data by adding features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add extracted features to training data\n",
    "\n",
    "df_train_fx = add_features(df_train_raw, 5)\n",
    "df_train_fx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add labels to training data using period of 30 cycles for classification\n",
    "\n",
    "df_train = prepare_train_data (df_train_fx, 30)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling average, rolling standard deviation, regression labels, and classification labels have been added to the training data.  \n",
    "\n",
    "Let us save the dataframe for later use in data exploration and modeling phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the training data to csv file for later use\n",
    "\n",
    "df_train.to_csv('data/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add extracted features to test data\n",
    "\n",
    "df_test_fx = add_features(df_test_raw, 5)\n",
    "df_test_fx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add labels to test data using period of 30 cycles for classification\n",
    "\n",
    "df_test = prepare_test_data(df_test_fx, df_truth, 30)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling average, rolling standard deviation, regression labels, and classification labels have been added to the test data.  \n",
    "\n",
    "Let us save the dataframe for later use in data exploration and modeling phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the test data to csv file for later use\n",
    "\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
